{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cudf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_transactions(path='./transactions_train.csv', parquet_path='transactions.pqt'):\n",
    "    transaction_columns = [\n",
    "        't_dat',\n",
    "        'customer_id',\n",
    "        'article_id'\n",
    "    ]\n",
    "    if os.path.exists(parquet_path):\n",
    "        print(f\"Loading cached Parquet file: {parquet_path}\")\n",
    "        return cudf.read_parquet(parquet_path)\n",
    "    \n",
    "    \n",
    "    print(f\"Processing raw CSV file: {path}\")\n",
    "    df = pd.read_csv(path)\n",
    "    df = df[transaction_columns]\n",
    "    \n",
    "    gdf = cudf.DataFrame.from_pandas(df)\n",
    "    gdf['customer_id'] = gdf['customer_id'].str[-16:].str.hex_to_int().astype('int64')\n",
    "    gdf['article_id'] = gdf['article_id'].astype('int32')\n",
    "    gdf['t_dat'] = cudf.to_datetime(gdf['t_dat'])\n",
    "    \n",
    "    gdf.to_parquet(parquet_path, index=False)\n",
    "    print(f\"Saved processed data to: {parquet_path}\")\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached Parquet file: transactions.pqt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = load_and_preprocess_transactions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = data.loc[(data[\"t_dat\"] >= datetime(2020, 9, 8)) & (data[\"t_dat\"] < datetime(2020, 9, 16))]\n",
    "train2 = data.loc[(data[\"t_dat\"] >= datetime(2020, 9, 1)) & (data[\"t_dat\"] < datetime(2020, 9, 8))]\n",
    "train3 = data.loc[(data[\"t_dat\"] >= datetime(2020, 8, 23)) & (data[\"t_dat\"] < datetime(2020, 9, 1))]\n",
    "train4 = data.loc[(data[\"t_dat\"] >= datetime(2020, 8, 15)) & (data[\"t_dat\"] < datetime(2020, 8, 23))]\n",
    "\n",
    "val = data.loc[data[\"t_dat\"] >= datetime(2020, 9, 16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_articles(df):\n",
    "    return df.groupby('customer_id').agg({'article_id': 'collect'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "positive_items_per_user1 = group_articles(train1)\n",
    "positive_items_per_user2 = group_articles(train2)\n",
    "positive_items_per_user3 = group_articles(train3)\n",
    "positive_items_per_user4 = group_articles(train4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = cudf.concat([train1, train2, train3, train4], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_date = datetime(2020, 9, 16)\n",
    "train['days_diff'] = (ref_date - train['t_dat']).dt.days\n",
    "train['pop_factor'] = 1 / (train['days_diff'] ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_items_group = train.groupby(['article_id'])['pop_factor'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_total_count = train.groupby(['article_id'])['article_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_total_count = train.groupby(['customer_id'])['customer_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['feedback'] = 1\n",
    "train= train.groupby(['customer_id', 'article_id']).agg({'feedback': 'sum'}).reset_index()\n",
    "train = train.merge(popular_items_group, on='article_id')\n",
    "train['feedback'] = train['feedback'] / train['pop_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['feedback'] = train['feedback'].clip(upper=5.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.044811e+06\n",
       "mean     8.252942e-01\n",
       "std      1.455205e+00\n",
       "min      5.373625e-03\n",
       "25%      6.460413e-02\n",
       "50%      1.771086e-01\n",
       "75%      6.486035e-01\n",
       "max      5.000000e+00\n",
       "Name: feedback, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "train['feedback'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_pop = data[(data['t_dat'] >= datetime(2020, 9, 1)) & (data['t_dat'] < datetime(2020, 9, 16))]\n",
    "train_pop['pop_factor'] = 1 / (ref_date - train_pop['t_dat']).dt.days\n",
    "popular_items_group = train_pop.groupby('article_id')['pop_factor'].sum()\n",
    "\n",
    "values = popular_items_group.to_pandas().values\n",
    "keys = popular_items_group.index.to_pandas().values\n",
    "_, popular_items = zip(*sorted(zip(values, keys))[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_most_freq_next_item_cudf(train_cudf):\n",
    "    \n",
    "    customer_ids = train_cudf['customer_id'].to_pandas().values\n",
    "    article_ids = train_cudf['article_id'].to_pandas().values\n",
    "\n",
    "    user_group = defaultdict(list)\n",
    "    for cid, aid in zip(customer_ids, article_ids):\n",
    "        user_group[cid].append(aid)\n",
    "\n",
    "    next_items = {}\n",
    "    for items in tqdm(user_group.values()):\n",
    "        for i in range(len(items) - 1):\n",
    "            item = items[i]\n",
    "            next_item = items[i + 1]\n",
    "            if item != next_item:\n",
    "                if item not in next_items:\n",
    "                    next_items[item] = []\n",
    "                next_items[item].append(next_item)\n",
    "\n",
    "    pred_next = {}\n",
    "    for item, next_list in next_items.items():\n",
    "        if len(next_list) >= 5:\n",
    "            counter = Counter(next_list)\n",
    "            most_common = counter.most_common(1)[0]\n",
    "            ratio = most_common[1] / len(next_list)\n",
    "            if ratio >= 0.1:\n",
    "                pred_next[item] = most_common[0]\n",
    "\n",
    "    return pred_next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254618/254618 [00:01<00:00, 173957.82it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_next = get_most_freq_next_item_cudf(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>feedback</th>\n",
       "      <th>pop_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922204863122141028</td>\n",
       "      <td>884319001</td>\n",
       "      <td>0.032755</td>\n",
       "      <td>30.529496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>371834049679164774</td>\n",
       "      <td>896170005</td>\n",
       "      <td>0.137613</td>\n",
       "      <td>7.266739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5531003004444685263</td>\n",
       "      <td>878079001</td>\n",
       "      <td>1.046723</td>\n",
       "      <td>0.955363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4967268061075549581</td>\n",
       "      <td>893133001</td>\n",
       "      <td>0.028883</td>\n",
       "      <td>34.622530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2717377534273311790</td>\n",
       "      <td>562245084</td>\n",
       "      <td>0.138711</td>\n",
       "      <td>7.209208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044806</th>\n",
       "      <td>6063253376555412458</td>\n",
       "      <td>832307007</td>\n",
       "      <td>0.018132</td>\n",
       "      <td>55.152144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044807</th>\n",
       "      <td>-2410089262427810293</td>\n",
       "      <td>727539001</td>\n",
       "      <td>1.874579</td>\n",
       "      <td>1.600359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044808</th>\n",
       "      <td>8005633013617885822</td>\n",
       "      <td>761406001</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>69.444728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044809</th>\n",
       "      <td>7483539152545825756</td>\n",
       "      <td>906114002</td>\n",
       "      <td>3.837562</td>\n",
       "      <td>0.521164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044810</th>\n",
       "      <td>7837664938802434151</td>\n",
       "      <td>816832010</td>\n",
       "      <td>0.271877</td>\n",
       "      <td>3.678136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1044811 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 customer_id  article_id  feedback  pop_factor\n",
       "0        1922204863122141028   884319001  0.032755   30.529496\n",
       "1         371834049679164774   896170005  0.137613    7.266739\n",
       "2       -5531003004444685263   878079001  1.046723    0.955363\n",
       "3       -4967268061075549581   893133001  0.028883   34.622530\n",
       "4       -2717377534273311790   562245084  0.138711    7.209208\n",
       "...                      ...         ...       ...         ...\n",
       "1044806  6063253376555412458   832307007  0.018132   55.152144\n",
       "1044807 -2410089262427810293   727539001  1.874579    1.600359\n",
       "1044808  8005633013617885822   761406001  0.014400   69.444728\n",
       "1044809  7483539152545825756   906114002  3.837562    0.521164\n",
       "1044810  7837664938802434151   816832010  0.271877    3.678136\n",
       "\n",
       "[1044811 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'reco'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreco\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrecommender\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunkSVD\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreco\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rmse\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# k = number of dimensions of the latent embedding. formatizer dict takes in names of the columns\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# for user, item and values/feedback/ratings respectively.\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'reco'"
     ]
    }
   ],
   "source": [
    "from reco.recommender import FunkSVD\n",
    "from reco.metrics import rmse\n",
    "\n",
    "# k = number of dimensions of the latent embedding. formatizer dict takes in names of the columns\n",
    "# for user, item and values/feedback/ratings respectively.\n",
    "\n",
    "svd = FunkSVD(k=8, learning_rate=0.008, regularizer = .01, iterations = 80, method = 'stochastic', bias=True)\n",
    "svd.fit(X=train, formatizer={'user':'customer_id', 'item':'article_id', 'value':'feedback'},verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=12):\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=12):\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "positive_items_val = val.groupby(['customer_id'])['article_id'].apply(list)\n",
    "val_users = positive_items_val.keys()\n",
    "val_items = []\n",
    "\n",
    "for i,user in tqdm(enumerate(val_users)):\n",
    "    val_items.append(positive_items_val[user])\n",
    "    \n",
    "print(\"Total users in validation:\", len(val_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "outputs = []\n",
    "cnt = 0\n",
    "\n",
    "popular_items = list(popular_items)\n",
    "\n",
    "for user in tqdm(val_users):\n",
    "    user_output = []\n",
    "    if user in positive_items_per_user1.keys():\n",
    "        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user1[user]).most_common()}\n",
    "        user_output += list(most_common_items_of_user.keys())[:12]\n",
    "    if user in positive_items_per_user2.keys():\n",
    "        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user2[user]).most_common()}\n",
    "        user_output += list(most_common_items_of_user.keys())[:12]\n",
    "    if user in positive_items_per_user3.keys():\n",
    "        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user3[user]).most_common()}\n",
    "        user_output += list(most_common_items_of_user.keys())[:12]\n",
    "    if user in positive_items_per_user4.keys():\n",
    "        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user4[user]).most_common()}\n",
    "        user_output += list(most_common_items_of_user.keys())[:12]\n",
    "    \n",
    "    user_output += [pred_next[item] for item in user_output if item in pred_next and pred_next[item] not in user_output]      \n",
    "    \n",
    "    user_output += list(popular_items[:12 - len(user_output)])\n",
    "    outputs.append(user_output)\n",
    "    \n",
    "print(\"mAP Score on Validation set:\", mapk(val_items, outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, prediction WITH the SVD reranking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "outputs = []\n",
    "cnt = 0\n",
    "\n",
    "popular_items = list(popular_items)\n",
    "userindexes = {svd.users[i]:i for i in range(len(svd.users))}\n",
    "\n",
    "for user in tqdm(val_users):\n",
    "    user_output = []\n",
    "    if user in positive_items_per_user1.keys():\n",
    "        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user1[user]).most_common()}\n",
    "        user_index = userindexes[user]\n",
    "        new_order = {}\n",
    "        for k in list(most_common_items_of_user.keys())[:20]:\n",
    "            try:\n",
    "                itemindex = svd.items.index(k)\n",
    "                pred_value = np.dot(svd.userfeatures[user_index], svd.itemfeatures[itemindex].T) + svd.item_bias[0, itemindex]\n",
    "            except:\n",
    "                pred_value = most_common_items_of_user[k]\n",
    "            new_order[k] = pred_value\n",
    "        user_output += [k for k, v in sorted(new_order.items(), key=lambda item: item[1])][:12]\n",
    "        \n",
    "    if user in positive_items_per_user2.keys():\n",
    "        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user2[user]).most_common()}\n",
    "        user_index = userindexes[user]\n",
    "        new_order = {}\n",
    "        for k in list(most_common_items_of_user.keys())[:20]:\n",
    "            try:\n",
    "                itemindex = svd.items.index(k)\n",
    "                pred_value = np.dot(svd.userfeatures[user_index], svd.itemfeatures[itemindex].T) + svd.item_bias[0, itemindex]\n",
    "            except:\n",
    "                pred_value = most_common_items_of_user[k]\n",
    "            new_order[k] = pred_value\n",
    "        user_output += [k for k, v in sorted(new_order.items(), key=lambda item: item[1])][:12]\n",
    "        \n",
    "    if user in positive_items_per_user3.keys():\n",
    "        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user3[user]).most_common()}\n",
    "        user_index = userindexes[user]\n",
    "        new_order = {}\n",
    "        for k in list(most_common_items_of_user.keys())[:20]:\n",
    "            try:\n",
    "                itemindex = svd.items.index(k)\n",
    "                pred_value = np.dot(svd.userfeatures[user_index], svd.itemfeatures[itemindex].T) + svd.item_bias[0, itemindex]\n",
    "            except:\n",
    "                pred_value = most_common_items_of_user[k]\n",
    "            new_order[k] = pred_value\n",
    "        user_output += [k for k, v in sorted(new_order.items(), key=lambda item: item[1])][:12]\n",
    "        \n",
    "    if user in positive_items_per_user4.keys():\n",
    "        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user4[user]).most_common()}\n",
    "        user_index = userindexes[user]\n",
    "        new_order = {}\n",
    "        for k in list(most_common_items_of_user.keys())[:20]:\n",
    "            try:\n",
    "                itemindex = svd.items.index(k)\n",
    "                pred_value = np.dot(svd.userfeatures[user_index], svd.itemfeatures[itemindex].T) + svd.item_bias[0, itemindex]\n",
    "            except:\n",
    "                pred_value = most_common_items_of_user[k]\n",
    "            new_order[k] = pred_value\n",
    "        user_output += [k for k, v in sorted(new_order.items(), key=lambda item: item[1])][:12]\n",
    "        \n",
    "    user_output += [pred_next[item] for item in user_output if item in pred_next and pred_next[item] not in user_output]      \n",
    "    \n",
    "    user_output += list(popular_items[:12 - len(user_output)])\n",
    "    outputs.append(user_output)\n",
    "    \n",
    "print(\"mAP Score on Validation set:\", mapk(val_items, outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decent jump of 0.001 I would say with 4 weeks of training data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "\n",
    "We will do all the same things all over again just with different time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train1 = data.loc[(data[\"t_dat\"] >= datetime.datetime(2020,9,16)) & (data['t_dat'] < datetime.datetime(2020,9,23))]\n",
    "train2 = data.loc[(data[\"t_dat\"] >= datetime.datetime(2020,9,8)) & (data['t_dat'] < datetime.datetime(2020,9,16))]\n",
    "train3 = data.loc[(data[\"t_dat\"] >= datetime.datetime(2020,8,31)) & (data['t_dat'] < datetime.datetime(2020,9,8))]\n",
    "train4 = data.loc[(data[\"t_dat\"] >= datetime.datetime(2020,8,23)) & (data['t_dat'] < datetime.datetime(2020,8,31))]\n",
    "\n",
    "positive_items_per_user1 = train1.groupby(['customer_id'])['article_id'].apply(list)\n",
    "positive_items_per_user2 = train2.groupby(['customer_id'])['article_id'].apply(list)\n",
    "positive_items_per_user3 = train3.groupby(['customer_id'])['article_id'].apply(list)\n",
    "positive_items_per_user4 = train4.groupby(['customer_id'])['article_id'].apply(list)\n",
    "\n",
    "train = pd.concat([train1, train2], axis=0)\n",
    "train['pop_factor'] = train['t_dat'].apply(lambda x: 1/(datetime.datetime(2020,9,23) - x).days)\n",
    "popular_items_group = train.groupby(['article_id'])['pop_factor'].sum()\n",
    "\n",
    "_, popular_items = zip(*sorted(zip(popular_items_group, popular_items_group.keys()))[::-1])\n",
    "\n",
    "user_group = pd.concat([train1, train2, train3, train4], axis=0).groupby(['customer_id'])['article_id'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# SVD\n",
    "train = pd.concat([train1, train2, train3, train4], axis=0)\n",
    "train['pop_factor'] = train['t_dat'].apply(lambda x: 1/(datetime.datetime(2020,9,23) - x).days**2)\n",
    "popular_items_group = train.groupby(['article_id'])['pop_factor'].sum()\n",
    "\n",
    "train['feedback'] = 1\n",
    "train = train.groupby(['customer_id', 'article_id']).sum().reset_index()\n",
    "\n",
    "train['feedback'] = train.apply(lambda row: row['feedback']/popular_items_group[row['article_id']], axis=1)\n",
    "\n",
    "train['feedback'] = train['feedback'].apply(lambda x: 5.0 if x>5.0 else x)\n",
    "train.drop(['price', 'sales_channel_id'], axis=1, inplace=True)\n",
    "train['feedback'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train.sample(frac=1).reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from reco.recommender import FunkSVD\n",
    "from reco.metrics import rmse\n",
    "\n",
    "f = FunkSVD(k=8, learning_rate=0.005, regularizer = .01, iterations = 200, method = 'stochastic', bias=True)\n",
    "f.fit(X=train, formatizer={'user':'customer_id', 'item':'article_id', 'value':'feedback'},verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv\")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "cnt = 0\n",
    "\n",
    "popular_items = list(popular_items)\n",
    "userindexes = {f.users[i]:i for i in range(len(f.users))}\n",
    "\n",
    "for user in tqdm(submission['customer_id']):\n",
    "    user_output = []\n",
    "    if user in positive_items_per_user1.keys():\n",
    "        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user1[user]).most_common()}\n",
    "        \n",
    "        user_index = userindexes[user]\n",
    "        new_order = {}\n",
    "        for k in list(most_common_items_of_user.keys())[:20]:\n",
    "            try:\n",
    "                itemindex = f.items.index(k)\n",
    "                pred_value = np.dot(f.userfeatures[user_index], f.itemfeatures[itemindex].T) + f.item_bias[0, itemindex]\n",
    "            except:\n",
    "                pred_value = most_common_items_of_user[k]\n",
    "            new_order[k] = pred_value\n",
    "        user_output += [k for k, v in sorted(new_order.items(), key=lambda item: item[1])][:12]\n",
    "        \n",
    "    if user in positive_items_per_user2.keys():\n",
    "        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user2[user]).most_common()}\n",
    "        \n",
    "        user_index = userindexes[user]\n",
    "        new_order = {}\n",
    "        for k in list(most_common_items_of_user.keys())[:20]:\n",
    "            try:\n",
    "                itemindex = f.items.index(k)\n",
    "                pred_value = np.dot(f.userfeatures[user_index], f.itemfeatures[itemindex].T) + f.item_bias[0, itemindex]\n",
    "            except:\n",
    "                pred_value = most_common_items_of_user[k]\n",
    "            new_order[k] = pred_value\n",
    "        user_output += [k for k, v in sorted(new_order.items(), key=lambda item: item[1])][:12]\n",
    "        \n",
    "    if user in positive_items_per_user3.keys():\n",
    "        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user3[user]).most_common()}\n",
    "        \n",
    "        user_index = userindexes[user]\n",
    "        new_order = {}\n",
    "        for k in list(most_common_items_of_user.keys())[:20]:\n",
    "            try:\n",
    "                itemindex = f.items.index(k)\n",
    "                pred_value = np.dot(f.userfeatures[user_index], f.itemfeatures[itemindex].T) + f.item_bias[0, itemindex]\n",
    "            except:\n",
    "                pred_value = most_common_items_of_user[k]\n",
    "            new_order[k] = pred_value\n",
    "        user_output += [k for k, v in sorted(new_order.items(), key=lambda item: item[1])][:12]\n",
    "        \n",
    "    if user in positive_items_per_user4.keys():\n",
    "        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user4[user]).most_common()}\n",
    "        \n",
    "        user_index = userindexes[user]\n",
    "        new_order = {}\n",
    "        for k in list(most_common_items_of_user.keys())[:20]:\n",
    "            try:\n",
    "                itemindex = f.items.index(k)\n",
    "                pred_value = np.dot(f.userfeatures[user_index], f.itemfeatures[itemindex].T) + f.item_bias[0, itemindex]\n",
    "            except:\n",
    "                pred_value = most_common_items_of_user[k]\n",
    "            new_order[k] = pred_value\n",
    "        user_output += [k for k, v in sorted(new_order.items(), key=lambda item: item[1])][:12]\n",
    "        \n",
    "    user_output += [pred_next[item] for item in user_output if item in pred_next and pred_next[item] not in user_output]      \n",
    "    \n",
    "    user_output += list(popular_items[:12 - len(user_output)])\n",
    "    outputs.append(user_output)\n",
    "    \n",
    "str_outputs = []\n",
    "for output in outputs:\n",
    "    str_outputs.append(\" \".join([str(x) for x in output]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission['prediction'] = str_outputs\n",
    "submission.to_csv(\"submissions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### That's it! Upvote and Enjoy!\n",
    "Examples of FunkSVD and FM are over at https://github.com/mayukh18/reco/tree/master/examples. I'll try to add an example of [Wide And Deep Network](https://arxiv.org/pdf/1606.07792.pdf) in the coming days. That is also a pretty cool model to try next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 3103714,
     "sourceId": 31254,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30162,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "recommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
